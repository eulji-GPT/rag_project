# main.py
from rag_pipeline import search_docs
from ollama_wrapper import get_ollama_answer

print("ğŸ’¬ Notion ê¸°ë°˜ RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” ('exit' ì…ë ¥ ì‹œ ì¢…ë£Œ):\n")

try:
    while True:
        query = input("ğŸ™‹ ì‚¬ìš©ì ì§ˆë¬¸: ")

        if query.lower() in ("exit", "quit"):
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # 1. ì§ˆë¬¸ â†’ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ChromaDBì—ì„œ)
        relevant_chunks, metadatas = search_docs(query)

        print("\nğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ:")
        for i, chunk in enumerate(relevant_chunks):
            title = metadatas[i].get("title", "ì œëª© ì—†ìŒ")
            print(f"[{i+1}] ({title}) {chunk[:100]}...")

        # 2. ê²€ìƒ‰ëœ ë¬¸ì„œ + ì§ˆë¬¸ â†’ Ollama ì‘ë‹µ
        response = get_ollama_answer(query, relevant_chunks, metadatas, stream=True)
        print("\nğŸ§  ì‘ë‹µ:", response)
        print("\n" + "-" * 50)

except KeyboardInterrupt:
    print("\nğŸ›‘ ê°•ì œ ì¢…ë£Œë¨.")
